---
title: "Chap. 3&4"
---

# A Formal Learning Model and Learning via Uniform Convergence

### PAC(Probably Approximately correct) learning

A hypothesis class $\mathcal{H}$ is PAC learnable
if there exist a function $m_H : (0; 1)^2 \to \mathcal{N}$ and a learning algorithm with the
following property: For every $\delta, \epsilon \in (0; 1)$, for every distribution $\mathcal{D}$ over $\mathcal{X}$, and
for every labeling function $f : X \to {0; 1}$, if the realizable assumption holds
with respect to $\mathcal{H};\mathcal{D};f$, then when running the learning algorithm on $m \geq 
m_H(\delta; \epsilon)$ i.i.d. examples generated by $\mathcal{D}$ and labeled by $\mathcal{f}$, the algorithm returns
a hypothesis h such that, with probability of at least $1- \delta$ (over the choice of the examples),$ \mathcal{L}_{\mathcal{D},f}(h) \leq \epsilon$