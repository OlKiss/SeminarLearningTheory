---
title: "Chap. 3&4"
---

# A Formal Learning Model and Learning via Uniform Convergence

### PAC(Probably Approximately correct) learning

A hypothesis class $\mathcal{H}$ is PAC learnable
if there exist a function $m_H : (0; 1)^2 \to \mathcal{N}$ and a learning algorithm with the
following property: For every $\delta, \epsilon \in (0; 1)$, for every distribution $\mathcal{D}$ over $\mathcal{X}$, and
for every labeling function $f : X \to {0; 1}$, if the realizable assumption holds
with respect to $\mathcal{H};\mathcal{D};f$, then when running the learning algorithm on $m \geq 
m_H(\delta; \epsilon)$ i.i.d. examples generated by $\mathcal{D}$ and labeled by $\mathcal{f}$, the algorithm returns
a hypothesis h such that, with probability of at least $1- \delta$ (over the choice of the examples),$ \mathcal{L}_{\mathcal{D},f}(h) \leq \epsilon$

$\epsilon$ - accuracy parameter (how far the output classifier from the optimal) - **Approximately**

$\delta$ - confidence parameter (how likely the classifier is to meet the accuracy requirement) - **Probably**

$m_H : (0; 1)^2 \to \mathcal{N}$ defines sample complexity (how many samples are needed)

### Corollary
Every finite hypothesis class is PAC learnable with following sample complexity:
\begin{center}
$m_H(\delta; \epsilon) \leq \frac{\log\frac{\|\mathcal{H}\|}{\delta}}{\epsilon}$
\end{center}

### More general learning rile:

* Realizability assumption does not hold quite often

* Labels may not be fully determined by the features which we measure

$\Rightarrow \mathcal{D}$ should be considered as a probability distribution over $\mathcal{X}\times\mathcal{Y}$.
In other words, $\mathcal{D}$ - joint distribution over domain points and labels.

Let us redefine $\mathcal{L}_{\mathcal{D}}(h):

$\mathcal{L}_{\mathcal{D}}(h) = \mathcal{P}_{(x,y)\sim D}[h(x)\neq y] = \mathcal{D}(\{(x,y): h(x) \neq y\})